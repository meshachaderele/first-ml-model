{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3HvK80AkOl7"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade scikeras\n",
        "# !pip show numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qitxbPRvKDaR"
      },
      "outputs": [],
      "source": [
        "# prompt: import  scikeras, keras and tensorflow, numpy,matplotlib\n",
        "\n",
        "# !pip install scikeras\n",
        "# !pip install pandas\n",
        "# !pip install tensorflow\n",
        "# !pip install keras\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install missingno\n",
        "# !pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxYawQl2BLzc"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler, MinMaxScaler\n",
        "from datetime import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "# from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load  the train.csv and the test.csv files.sample(n=10000,random_state=37)\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')"
      ],
      "metadata": {
        "id": "yrCZEYY_kIBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gYbTs2UFwuo"
      },
      "outputs": [],
      "source": [
        "# Determine car year\n",
        "# Calculate current year\n",
        "current_year = datetime.now().year\n",
        "\n",
        "# Calculate the age of the car\n",
        "train['car_age'] = current_year - train['year']\n",
        "test['car_age'] = current_year - test['year']\n",
        "# Drop the original 'year' column\n",
        "train.drop(columns=['year'], inplace=True)\n",
        "test.drop(columns=['year'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0uWR4dJFyGL"
      },
      "outputs": [],
      "source": [
        "# delete all rows with price of 0\n",
        "train = train[train['price'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ_-hDMTF2lx"
      },
      "outputs": [],
      "source": [
        "# Drop the id column\n",
        "# train.drop(columns=['id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBbdHsl7F5TH"
      },
      "outputs": [],
      "source": [
        "# Convert string values in the 'kilometers' column to numerical values and return the maximum\n",
        "def convert_to_max_kilometer(value):\n",
        "    if isinstance(value, str):\n",
        "        parts = value.split(' to ')\n",
        "        if len(parts) == 1:  # Single value\n",
        "            return int(parts[0])\n",
        "        else:\n",
        "            return int(parts[1])  # Maximum of the range\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "# Apply the function to each value in the 'kilometers' column\n",
        "train['max_kilometer'] = train['kilometers'].apply(convert_to_max_kilometer)\n",
        "test['max_kilometer'] = test['kilometers'].apply(convert_to_max_kilometer)\n",
        "\n",
        "# Drop the original 'kilometers' column\n",
        "train.drop(columns=['kilometers'], inplace=True)\n",
        "test.drop(columns=['kilometers'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8UZrPW7F8im"
      },
      "outputs": [],
      "source": [
        "# Impute missing values for categorical features (e.g., body_type) with a new category 'unknown'\n",
        "# Define a function to generate a random string\n",
        "def generate_random_string(length=8):\n",
        "    letters = string.ascii_lowercase\n",
        "    return ''.join(random.choice(letters) for _ in range(length))\n",
        "\n",
        "# train['body_type'].fillna('unknown', inplace=True)\n",
        "# test['body_type'].fillna('unknown', inplace=True)\n",
        "train['body_type'].fillna(generate_random_string(), inplace=True)\n",
        "test['body_type'].fillna(generate_random_string(), inplace=True)\n",
        "\n",
        "# Drop rows with more than three missing data fields\n",
        "train.dropna(thresh=train.shape[1]-3, inplace=True)\n",
        "\n",
        "# Step 2: Encode Categorical Variables\n",
        "# Initialize LabelEncoder\n",
        "label_encoders = {}\n",
        "\n",
        "# Encode categorical variables with LabelEncoder\n",
        "categorical_columns = ['brand', 'city', 'region', 'model', 'transmission_type','body_type' ]\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    train[col] = label_encoders[col].fit_transform(train[col])\n",
        "    test[col] = label_encoders[col].transform(test[col])\n",
        "\n",
        "\n",
        "train.drop('created_at_first', axis=1, inplace=True)\n",
        "test.drop('created_at_first', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_uDikT2GC30"
      },
      "outputs": [],
      "source": [
        "# Handle Outliers\n",
        "# Identify and handle outliers in numerical features using winsorization\n",
        "def handle_outliers(df, columns):\n",
        "    for col in columns:\n",
        "        # Calculate the 1st and 99th percentile\n",
        "        p1 = df[col].quantile(0.01)\n",
        "        p99 = df[col].quantile(0.99)\n",
        "\n",
        "        # Winsorization: Replace outliers with the nearest valid value within the percentile thresholds\n",
        "        df[col] = df[col].clip(lower=p1, upper=p99)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T_2Tx5KGGXn"
      },
      "outputs": [],
      "source": [
        "# Normalize/Scale Numerical Features\n",
        "# Scale numerical features to a similar range using RobustScaler\n",
        "def scale_numerical_features(df, columns):\n",
        "    scaler = MinMaxScaler()  # Initialize RobustScaler RobustScaler()\n",
        "    df[columns] = scaler.fit_transform(df[columns])  # Fit and transform the selected numerical features\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "metadata": {
        "id": "DmMFFL5kacTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e37f92-14df-4d83-d64a-1905eda5e328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            id  city  region  body_type  transmission_type  brand  model  \\\n",
            "0            1   276      25          0                  1     14     38   \n",
            "1            2   239       3          2                  2     43      7   \n",
            "2            3   222      17          3                  2     28     22   \n",
            "3            4   251      18          6                  0      4     27   \n",
            "4            5    12       6          2                  2     24     35   \n",
            "...        ...   ...     ...        ...                ...    ...    ...   \n",
            "766954  766955   209       6          6                  2     14     40   \n",
            "766955  766956    99       6          6                  0      3      3   \n",
            "766956  766957   117      16          6                  2      4     27   \n",
            "766957  766958   196       1          6                  2     22     45   \n",
            "766958  766959   300      23          1                  1      4     27   \n",
            "\n",
            "         price  car_age  max_kilometer  \n",
            "0       8900.0     23.0         9999.0  \n",
            "1       5400.0     21.0         9999.0  \n",
            "2       9500.0     16.0         9999.0  \n",
            "3       5100.0     22.0         9999.0  \n",
            "4       7000.0     19.0        99999.0  \n",
            "...        ...      ...            ...  \n",
            "766954  9800.0      9.0        69999.0  \n",
            "766955  1500.0     31.0         9999.0  \n",
            "766956  8600.0     21.0         9999.0  \n",
            "766957  6200.0     19.0       139999.0  \n",
            "766958  3000.0     38.0         9999.0  \n",
            "\n",
            "[757691 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete all rows in the car_age column with age that is above the 70percentiles but with a price that is above 50 percentiles\n",
        "\n",
        "\n",
        "train = train.drop(train[(train['car_age'] > train['car_age'].quantile(0.65)) & (train['price'] > train['price'].quantile(0.5))].index)  #rmsle score: 0.35\n",
        "# train = train.drop(train[(train['car_age'] > train['car_age'].quantile(0.55)) & (train['price'] > train['price'].quantile(0.5))].index) #rmsle score: 0.33\n",
        "# train = train.drop(train[(train['car_age'] > train['car_age'].quantile(0.75)) & (train['price'] > train['price'].quantile(0.25))].index)  #rmsle score: 0.3005\n",
        "#train = train.drop(train[(train['car_age'] > train['car_age'].quantile(0.55)) & (train['price'] > train['price'].quantile(0.5))].index)  #rmsle score: 0.263\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bx7YVymIWXV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train = train.drop(train[(train['car_age'] < train['car_age'].quantile(0.3)) & (train['price'] < train['price'].quantile(0.35))].index)  #rmsle score: 0.35\n",
        "# train = train.drop(train[(train['car_age'] < train['car_age'].quantile(0.55)) & (train['price'] < train['price'].quantile(0.35))].index) #rmsle score: 0.33\n",
        "# train = train.drop(train[(train['car_age'] < train['car_age'].quantile(0.25)) & (train['price'] < train['price'].quantile(0.75))].index)  #rmsle score: 0.3005\n",
        "#train = train.drop(train[(train['car_age'] < train['car_age'].quantile(0.55)) & (train['price'] < train['price'].quantile(0.35))].index) #rmsle score: 0.263\n",
        "\n"
      ],
      "metadata": {
        "id": "_XCUj3iybj2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete every row that has a max-kilometer that is wit delete all rows in the max-kilometers column if its value that is above the 70percentiles but with a price that is above 40 percentiles\n",
        "\n",
        "train = train.drop(train[(train['max_kilometer'] > train['max_kilometer'].quantile(0.6)) & (train['price'] > train['price'].quantile(0.5))].index)  #rmsle score: 0.35\n",
        "# train = train.drop(train[(train['max_kilometer'] > train['max_kilometer'].quantile(0.55)) & (train['price'] > train['price'].quantile(0.5))].index) #rmsle score: 0.33\n",
        "# train = train.drop(train[(train['max_kilometer'] > train['max_kilometer'].quantile(0.25)) & (train['price'] > train['price'].quantile(0.75))].index)  #rmsle score: 0.3005\n",
        "#train = train.drop(train[(train['max_kilometer'] > train['max_kilometer'].quantile(0.25)) & (train['price'] > train['price'].quantile(0.75))].index)  #rmsle score: 0.263\n",
        "\n"
      ],
      "metadata": {
        "id": "KaYysJLnfmPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete all rows in the max-kilometers column with value that is  within the 15 percentiles but with a price that is below 35 percentiles\n",
        "\n",
        "\n",
        "train = train.drop(train[(train['max_kilometer'] < train['max_kilometer'].quantile(0.3)) & (train['price'] < train['price'].quantile(0.35))].index) #rmsle score: 0.35\n",
        "# train = train.drop(train[(train['max_kilometer'] < train['max_kilometer'].quantile(0.55)) & (train['price'] < train['price'].quantile(0.35))].index) #rmsle score: 0.33\n",
        "# train = train.drop(train[(train['max_kilometer'] < train['max_kilometer'].quantile(0.75)) & (train['price'] < train['price'].quantile(0.25))].index) #rmsle score: 0.3005\n",
        "#train = train.drop(train[(train['max_kilometer'] < train['max_kilometer'].quantile(0.75)) & (train['price'] < train['price'].quantile(0.25))].index) #rmsle score: 0.263"
      ],
      "metadata": {
        "id": "9-AFPDJvfmkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_H1w-agGI_I"
      },
      "outputs": [],
      "source": [
        "# List of numerical columns to handle outliers and scale\n",
        "numerical_columns = ['max_kilometer', 'car_age', 'price']  # Assuming these are the numerical features\n",
        "\n",
        "# Handle outliers\n",
        "train = handle_outliers(train, numerical_columns)\n",
        "\n",
        "# Normalize/Scale Numerical Features\n",
        "scaler = MinMaxScaler()\n",
        "train[numerical_columns] = scaler.fit(train[numerical_columns])\n",
        "train = scaler.transform(train)\n",
        "\n",
        "[columns] = scaler.fit_transform(df[columns])\n",
        "# test = scaler.transform(test)\n",
        "# train = scale_numerical_features(train, ['max_kilometer', 'car_age',])\n",
        "# test = scale_numerical_features(test, ['max_kilometer', 'car_age',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BwZES0MGMLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "2c04f2ad-4bb5-4bf1-cb27-58be3b4e9e5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-336-fec3a273a3d3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_with_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     plt.title(f'{col} vs. price')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Calculate correlation between each feature and the target variable (price)\n",
        "correlation_with_price = train.corrwith(train['price']).sort_values(ascending=False)\n",
        "\n",
        "# Plot each column against the price\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, col in enumerate(correlation_with_price.index):\n",
        "    plt.subplot(3, 5, i + 1)\n",
        "    plt.scatter(train[col], train['price'], alpha=0.5)\n",
        "#     plt.title(f'{col} vs. price')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Price')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClLhsU00GSWq"
      },
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "correlation_matrix = train.corr()\n",
        "\n",
        "# Extract the correlation of each feature with the target variable (price)\n",
        "feature_correlation = correlation_matrix['price'].abs().sort_values(ascending=False)\n",
        "\n",
        "# Print the most correlated features\n",
        "print(\"Most correlated features with price:\")\n",
        "print(feature_correlation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcUUQYx1GXBc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute Root-Mean-Squared-Logarithmic-Error (RMSLE) loss between y_true and y_pred.\n",
        "    \"\"\"\n",
        "    # squared_log_error = tf.square(tf.math.log(y_true + 1) - tf.math.log(y_pred + 1))\n",
        "    # mean_squared_log_error = tf.reduce_mean(squared_log_error, axis=-1)\n",
        "    # return tf.sqrt(mean_squared_log_error)\n",
        "    assert len(y_true) == len(y_pred), \"Lengths of true and predicted values must match\"\n",
        "\n",
        "    # Transform true and predicted values using natural logarithm\n",
        "    y_true_log = np.log1p(y_true)\n",
        "    y_pred_log = np.log1p(y_pred)\n",
        "\n",
        "    # Compute squared log error\n",
        "    squared_log_error = (y_true_log - y_pred_log) ** 2\n",
        "\n",
        "    # Compute mean squared log error and take square root\n",
        "    mean_squared_log_error = np.mean(squared_log_error)\n",
        "    rmsle = np.sqrt(mean_squared_log_error)\n",
        "\n",
        "    return rmsle\n",
        "\n",
        "\n",
        "# Use RMSLE as the loss function when compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfwWowhYGZ5m"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        # Input layer with four neurons\n",
        "        Dense(16, input_shape=(4,), activation='relu'),  # 16 neurons in the hidden layer\n",
        "        # Output layer with a single neuron for regression\n",
        "        Dense(1, activation='linear')  # Linear activation for regression\n",
        "    ])\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    # model.compile(optimizer=\"adam\", loss=rmsle)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztVrdJ-GeVD"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the KerasRegressor wrapper with the defined model\n",
        "\n",
        "keras_regressor = KerasRegressor(build_fn=create_model, epochs=10, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8yL-HGrKuEJ"
      },
      "outputs": [],
      "source": [
        "# Prepare the input features (X_train) and target variable (y_train)\n",
        "train.fillna(train.mean(),inplace=True)\n",
        "\n",
        "X = train[['car_age', 'transmission_type', 'max_kilometer','body_type']]\n",
        "y = train['price']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xtci25cGlrQ"
      },
      "outputs": [],
      "source": [
        "# Fit the model to the training data\n",
        "keras_regressor.fit(X_train,y_train)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkoVDo-dGon4"
      },
      "outputs": [],
      "source": [
        "# Assuming X_val and y_val are the validation set\n",
        "# Check for missing values in the validation data\n",
        "\n",
        "# print(\"\\nNo missing values found in the data.\")\n",
        "# score = keras_regressor.score(X_val, y_val)\n",
        "# print(\"Validation Set Score:\", score)\n",
        "sns.scatterplot(x=y_val,y=y_val)\n",
        "data = keras_regressor.predict(X_val)\n",
        "sns.scatterplot(y= data,x = y_val, label=f'rmsle score: {np.sqrt(np.mean(np.square(np.log1p(y_val) - np.log1p(data))))}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions on the validation set\n",
        "mse_predictions = keras_regressor.predict(X_val)\n",
        "\n",
        "# Extract true values from the validation set\n",
        "true_values = y_val.values\n",
        "\n",
        "# Compute RMSLE\n",
        "rmsle_score = rmsle(true_values, mse_predictions)\n",
        "print(\"RMSLE Score:\", rmsle_score)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle = np.sqrt(np.mean(np.square(np.log1p(y_val) - np.log1p(mse_predictions))))\n",
        "print(\"RMSLE on Validation Set: %.4f\" % rmsle)"
      ],
      "metadata": {
        "id": "oJ6Q6RwLbbLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgg2csjsGrWB"
      },
      "outputs": [],
      "source": [
        "# Obtain predictions for the test data\n",
        "predictions = keras_regressor.predict(test[['car_age', 'transmission_type', 'max_kilometer','body_type']])\n",
        "\n",
        "# Combine predictions with corresponding IDs\n",
        "predicted_prices = pd.DataFrame({'id': test['id'], 'price': predictions})\n",
        "print(predicted_prices)\n",
        "# Export the DataFrame to a CSV file\n",
        "predicted_prices.to_csv('submission.csv', index=False, mode='w')\n",
        "# predictions = keras_regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taR5kkzpGul3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}